---
title: "Conducting EDA on Corruption Data"
author: "Andre Fernandes, Keenan Szulik, and Erik Hou"
date: "`r format(Sys.time(),'%m/%d/%Y')`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- ################################### -->
<!-- # Erik's section Begins -->
<!-- ################################### -->

## Introduction

This analysis is motivated by the following research question:


__"Is there any relationship between corruption and parking violations both before and after 2002? If so, are there any other relevant explanatory variables?"__

The question will be addressed by exploratory data analysis techniques. We have been asked to imagine that we were hired by the World Bank to explore the influence cultural norms and legal enforcement have on controlling corruption. To operationalize the analysis, the assignment looks at the parking behavior of United Nations officials in Manhattan.

Until 2002, UN diplomats were protected by diplomatic immunity: they were not subject to parking enforcement actions and their actions were solely constrained by cultural norms. In 2002, the parking authority acquired the right to confiscate diplomatic license plates of the violators. As a result, their parking behavior was constrained by both cultural norms and the legal penalties.

We have been given a dataset of a selection of UN diplomatic missions, which includes a target variable, *violations*; a label for before and after the parking enforcement change, *prepost*; and other essential variables, like corruption index and  continent regions.

### Setup

First, we load some of the packages we will need for the analysis and the data into R.

Load the data:
```{r, echo=TRUE}
source("utils/functions.R")
df <- load_rda('data/Corrupt.Rdata')
```

### Overview of the data structure

We have `r nrow(df)` observations.
```{r}
nrow(df)
```

We have `r length(colnames(df))` variables in the dataset:
```{r}
str(df)
```

Look at the summary of the dataset:
```{r}
summary(df)
```

Examine the first ten rows of the dataset:
```{r}
head(df, 10)
```

### Data Selection and Cleaning

From examining the data summary and the first ten rows, we see  many NA values in the key variable fields, such as violations and corruption. Also notice that, in the field prepost, we have blanks. 

It is necessary to clean the data by taking out the records with the blank or NA essential fields before starting analysis on relevant variables:

```{r}
df[df=="" | df=="NA"] = NA  #set all the blanks and "NA" to NA

#exclude the records having NAs in at least one of the essential fields
df_clean = subset(df, !is.na(wbcode) & !is.na(prepost) & !is.na(violations) & !is.na(corruption))

```

Do another count row, we note that the number of observations dropped in the cleaning process was `r nrow(df)-nrow(df_clean)`

```{r}
nrow(df)-nrow(df_clean) #number of observations dropped when cleaning data
```

One last step before starting univariate analysis of key variables is to make sure that, in our cleaned dataset, we have exactly two records per country, one before and one after 2002. Because,

1. With a missing *pre* or *pos* record, it would be difficult to compare country behavior pre and post the policy change. 
2. If the dataset includes countries that had more than one pre and/or one post record, further cleaning or manipulation would be required to appropriately weigh different observations.


```{r}
length(unique(df_clean[df_clean$prepost == "pre",]$wbcode))  #the total number of distinct countries in the data set with prepost == "pre"
length(unique(df_clean[df_clean$prepost == "pos",]$wbcode))  #the total number of distinct countries in the data set with prepost == "pos"
length(unique(df_clean$wbcode))  #the total number of unique countries
nrow(df_clean)  #the total number observations in the data set
```

From the above counts, we note that, in the dataset, `r length(unique(df_clean[df_clean$prepost == "pre",]$wbcode)) ` unique coutries having *prepost* field as *pre* and `r length(unique(df_clean[df_clean$prepost == "pos",]$wbcode)) ` unique countries having prepost field being *pos*. Because we know that we have exactly `r length(unique(df_clean$wbcode))` different countries in the dataset, so we can conclude, we have `r length(unique(df_clean$wbcode))` unique countries with each of them having one pre and one post record. There are no duplicates because the 2 times `r length(unique(df_clean$wbcode))` is equal to the total observation count of `r nrow(df_clean)`.

Finally, we have made sure our dataset is clean enough for our subseqent analysis.


## Univariate Analysis of Key Variables

Now we start the univariate analysis.

### Target Variable: Violations

Let's look at the target variable __violations__:

```{r, echo=TRUE}
summary(df_clean$violations)
sd(df_clean$violations)
hist(df_clean$violations,20,xlab = "Violations", main = "Histogram of Violations")
```

There are several features of the variables worth highlighting:

1. All the values are non-negative.
2. From both the histogram and the numeric summary, we can see that the values are very clustered on the lower end: more than 50% of the values are less than 6.
3. The distribution is right-skewed, with large outliers. This causes the mean to be greater than the median and a high standard deviation, around 302.

Since there are `r nrow(df_clean[df_clean$violations == 0,])` violation data points with the value of zero, as well as outliers--a histogram of $log(volations + 1)$ will help us better visualize the distribution. While drawing the histogram, we adjust the positions of the bins so the first bar is centered around zero. 
```{r}
nrow(df_clean[df_clean$violations == 0,])
```
```{r}
hist(log(df_clean$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations")
```

Notice that the frequency distribution appears to have two local peaks, one in (-0.25,0.25) and one in (4.25,4.75). This probably is caused by the change of policy where there were more violations before 2002 and less violation after 2002. We will inspect this further.

Two histograms of violations before and after the change of policy prove the assumption.
```{r}
hist(log(df_clean[df_clean$prepost == "pre",]$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations until 2002")
hist(log(df_clean[df_clean$prepost == "pos",]$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations starting 2002")
```

From the above graphic, we demonstrated the shift in the distribution of violation before and after the policy change.

### Variable: Corruption

Next, we move on to the other key variable, corruption.

First step is to look at the numeric summary of the variable and its histogram:

```{r}
summary(df_clean$corruption)
sd(df_clean$corruption)
hist(df_clean$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))
```

We draw the histograms of corruption of pre and post the policy change separately to compare:


```{r}
hist(df_clean[df_clean$prepost == "pre",]$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption until 2002")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))
hist(df_clean[df_clean$prepost == "pos",]$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption starting 2002")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))

```

Note that the two histograms appear identical, which likely means that this dataset treats corruption as a constant variable over time. To further check, we test if for each country the corruption is the same pre and post 2002.

```{r}
nrow(unique(df_clean[,c("wbcode", "corruption")]))
```

Several key features of the variable *corruption*:

1. Through making sure that the number of unique combinations of *wbcode* and *corruption* is the same as the number of unique wbcodes, we are sure that the dataset has corruption as a constant for each country over time.
2. We can see that the histogram appears to have two local peaks: one at around 0.75 and another at around -2.5.
3. This distribution is left-skewed, with most countries having the values between 0 and 1.
4. Some outliers cluster close to the lower local peak at -2.5.


<!-- ################################### -->
<!-- # Andre's section Begins -->
<!-- ################################### -->

## Analysis of Key Relationships

In this section, we will be conducting multivariate analysis on our corruption data. This section will be divided into two segments comprised of __correlations for numerical variables__ and a deeper dive into variable relationships while observing the __prepost__ variable.

### Analyzing correlations among continuous variables

#### All line items

Here, we do a quick look at correlation of the numerical variables. It appears that most variables in this dataset is static between the two snapshot dates (as mentioned above).

1. Violations and fines are perfectly correlated, so appear to they tell us the same information about the data. We will check to see if they are identical later in this analysis.
2. Since we know that the *prepost* variable captures a time element, we will be viewing the correlations in each of the _pre_ and _pos_ subset groups.
3. Staff, Spouse, and Car Total have a high positive correlation, which makes sense when we think of the semantic meaning of these variables.
4. GDP and Corruption have a very high negative correlation. This is not a surprising given the semantic definitions.
5. There are many other relationships to look at, but for the sake of brevity, we will end the analysis into the combined data correlations here.


_The plot_correlation function was moved to the functions.R file. In it, we use the **cor function** with the following parameter **use="pairwise.complete.obs"** in order to drop the minimal number of observations when computing the correlations between two variables. Also, I only calculate the correlation for variables with the attribute **is.numeric(x)==TRUE** AND **length(unique(x))>10**, to keep factor variables from being calculated as numeric, AND we exclude the variable **distUNplz** since we could not figure out its definition with the provided information._

```{r, echo=TRUE, fig.width=13, fig.height=7}

# all lines
plot_correlation(df_clean, 10)

```

#### Pre and Post 2002

1. The interesting observation from comparing __pre__ and __post__ 2002 correlations is that __milaid__ and __totaid__ show slight positive correlations with __violations__ and __fines__ pre 2002. Meanwhile, during the __post 2002__ period, those correlations have a near zero *R value*.
2. There's a shortage of information about the dataset and how variables are captured and defined, so we will not be able to explain why the correlations are so different between the aforementioned variables during the two snapshots of time.

Here, we will subset out data to _prepost == 'pre'_.

```{r, echo=TRUE, fig.width=13, fig.height=7}

# pre lines
plot_correlation(df_clean %>% filter(prepost=='pre'), 10)

```

Here, we will subset out data to _prepost == 'pos'_.

```{r, echo=TRUE, fig.width=13, fig.height=7}

# post lines
plot_correlation(df_clean %>% filter(prepost=='pos'), 10)

```

#### Looking further into the relationship between violations and fines

We observed a very strong correlation between __violations__ and __fines__, so now let's plot a scatterplot with these two variables and add the bet fit line. Please note that we saw the correlation metrics prior to even adding a log transformation, so we will keep the variables as is for this graph.

The variables indeed appear to be perfectly correlated. This makes sense since fines are likely violations multiplied by a scalar.
```{r, echo=TRUE, fig.width=13, fig.height=7}

# regular
plot_scatter <- ggplot(df_clean, aes(x=fines, y=violations)) + 
                    geom_point()+ geom_smooth(method=lm,  linetype="dashed", color="darkred", fill="blue")+ 
                    geom_text(x = 40000, y = 2000, label = lm_eqn(df_clean, 'fines', 'violations'), parse = TRUE)+
                    labs(title = "Scatter Plot for Violations and Fines with Linear Model")
plot(plot_scatter)

```

### Deep dive into variable relationships with violations while considering the prepost 2002 timestamp

In this section, we will analyze variables that we believe are important. We will not cover all variables for brevity.

#### Region

One of the key categorical variables to observe is __region__. Although the given dataset only provides an integer factor for the regions, we were able to use the regional indicators to map the integer factors back to actual region names. Also, please note that the African country of __Zaire__ had a missing value for __region__. Since we were able to do a quick internet search and discovered that __Zaire__ is in __Africa__, we altered the record when creating the __region_clean__ variable.

What we were able to observe:

1. North America region has the lowest mean __log(violations+1)__ before and after 2002.
2. Middle East region has the largest interquartile range before and after 2002.
3. The target variable is much lower after 2002 (as we would expect since countries are now paying their fines, which lowers the total unpaid level)

```{r, echo=TRUE, fig.width=13, fig.height=7}

df_clean$region_clean <- ifelse(is.na(df_clean$region),6,df_clean$region)
df_clean$region_clean <- as.factor(df_clean$region_clean)
levels(df_clean$region_clean) <- c('n_america', 's_america', 'europe', 'asia', 'oceania', 'africa', 'mid_east')

plot_vars(df_clean, 'violations', 'region_clean', 'cat', 'prepost')

```

#### Corruption

One of the key numerical variables to observe is __corruption__. 

What we were able to observe:

1. Corruption has a more positive relationship with the target variable before 2002 than after.
2. The value for the corruption variable is static, so they are not different between the two snapshots in time. It is strange to want this variable to be static since we would expect that the corruption index changes over time.

```{r, echo=TRUE, fig.width=13, fig.height=7}

plot_vars(df_clean, 'violations', 'corruption', 'numeric', 'prepost')

```

#### Fines

Another key numerical variables to observe is __fines__. We already plotted the relationship between violations and fines earlier, so here we take a look at the relationship between the log transformations of the two variables.

What we were able to observe:

1. There still remains a clear relationship between the log transformations of the two variables.
2. The relationships appear to be less linear than before, but the linear estimator is still okay in this case.
3. If a predictive model were built to predict violations, this is a classic example of data leakage. If you attempt to use __fines__ as a predictor for __violations__, you would not have __fines__ information at the time of prediction. This means that this variable is only available in our data because we are looking at historical records. 


```{r, echo=TRUE, fig.width=13, fig.height=7}
df_clean$log_fines <- log(df_clean$fines +1)
plot_vars(df_clean, 'violations', 'log_fines', 'numeric', 'prepost')

```

#### Trade

What we were able to observe:

1. The relationship between trade and the log transformation of violation is all over the place. We would not trust the linear models in this case.

```{r, echo=TRUE, fig.width=13, fig.height=7}

df_clean$log_trade <- log(df_clean$trade+1)
plot_vars(df_clean, 'violations', 'log_trade', 'numeric', 'prepost')


```

#### Total Cars

What we were able to observe:

1. There appears to be a positive relationship between number of total cars and the log transformation of violations. This makes intuitive sense.

```{r, echo=TRUE, fig.width=13, fig.height=7}

plot_vars(df_clean, 'violations', 'cars_total', 'numeric', 'prepost')


```


<!-- ################################### -->
<!-- # Keenan's section Begins -->
<!-- ################################### -->

### Analysis of Secondary Effects

#### Total Aid

Among the remaining variables provided in the dataset, one of the most fascinating was *totaid*, which was slightly correlated with the number of violations that a given country received before immunity was granted, but became largely neutral after the change in policy.

As we see below, the stark difference in these visualizations (and resultant correlations) demonstrates the strong relationship between the amount of aid that a country received and the number of parking violations it received before the violation policy was altered. This is interesting, as we saw an unclear relationship between the log transformation of violations and that of trade, but we see one related to the amount of aid a country receives.

```{r, echo=TRUE, fig.width=13, fig.height=7}

df_clean$log_totaid <- log(df_clean$totaid+1)
plot_vars(df_clean, 'violations', 'log_totaid', 'numeric', 'prepost')

```

Narratively, this could, perhaps, be an illustrative example of the impact of reliance on the United States with the desire to comply with their instituted laws: prior to a more strictly instituted policy, countries that were dependent on foreign aid were highly likely to violate parking regulations; however, after the United States began enforcing their policy, other countries became much more likely to comply.

That said, this could be a false narrative: there is a slightly negative correlation between "totaid" and country GDP, meaning that these violators could decide to better comply with local jurisdiction because they have less tolerance for paying significant fines.

#### Majority Muslim country indicator

We are provided in the data set variables for __pctmuslim__ and __majoritymuslim__, which are respectively percent of population that is muslim and a flag that captures whether or not a country is majority muslim. Unfortunately, the levels for the __majoritymuslim__ are not intuitive from the information we were provided, so we created our own flag using the __pctmuslim__ variable.

What we were able to observe:

1. There are many countries in these UN events that were not majority muslim than those that are.
2. We are unable to learn much information about this variable. Majority muslim countries appear to have higher log violations, but that difference is so small that it is likely due to noise. Majority muslim countries also represent less points in our data, which makes any aggregate information even more susceptible to noise.

```{r, echo=TRUE, fig.width=13, fig.height=7}
df_clean$maj_musl_ind <- ifelse(is.na(df_clean$pctmuslim), 'missing', ifelse(df_clean$pctmuslim>.5,'yes','no'))
plot_vars(df_clean, 'violations', 'maj_musl_ind', 'cat', 'prepost')


```

#### Violations per Staff Member

An additional way of framing the question of the number of violations by the diplomats of a given country, relative to that country's level of corruption, is by looking at the number of violations per staff member. Logically, a country with more individuals at risk of violating parking policy will be more likely to more likely to, in fact, violate parking policy, but we see a surprisingly strong trend when viewing the log transformation of this variable relative to corruption.

```{r, echo=TRUE, fig.width=13, fig.height=7}
df_clean$violations_per_staff <- (df_clean$violations / df_clean$staff)
plot_vars(df_clean, 'violations_per_staff', 'corruption', 'numeric', 'prepost')

```

We can plainly see here that the log transformation of violations per staff member is correlated with corruption both before and after the policy change, but we see that the correlation is quite strong prior to the change.


### Conclusion

After performing our exploratory data analysis on the given dataset on diplomatic parking violations in the United States before and after 2002, we are left to form conclusions to our initial question: is there any relationship between the corruption level of a country and the number of parking violations it received?

We learned that we do have robust data detailing the violation history of 149 unique countries before and after the policy change, and that the most common number of violations for a given country was zero. That said, we also saw a large variance in the number of violations that a country may receive, even when looking at countries within the same region. For example, Europe and the Middle East had the largest interquartile ranges of the log transformation of their violation count before 2002, yet showed a dramatic lessening of that range after the policy change.

But what does this mean for our target variables: corruption and violations? We discovered that there is a positive relationship between the number of violations and a country's corruption both before and after 2002. But we also see that the correlation is stronger after 2002. Although countries across the world saw themselves committing fewer parking violations, country's that were more corrupt tended to decrease their violations by less. This supports the hypothesis that there is a positive relationship between the level of corruption of a country and the willingness of its diplomats to violate parking laws, though it does not quantify that relationship.

Other questions that arose, to which we have incomplete answers, include: 

1) Is there a relationship between trade with the United States and violations? Not particularly.
2) Do country diplomats bringing higher total cars to the UN tend to have more parking violations? Typically, yes.
3) Are countries who receive more aid more sensitive to changes in fine enforcement policies? Dramatically so.
4) Was there a language barrier between non-English speaking countries and the law enforcement of the United States that may have caused more confusion around diplomatic parking policy?

One final point that we would like to state that, at times, the variables within the provided dataset were presented with limited documentation, which inhibited our ability to perform as robust of an analysis as hoped. 


<style>
    body .main-container {
        max-width: 1600px;
    }
</style>
