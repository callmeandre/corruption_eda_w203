---
title: "Conducting EDA on Corruption Data"
author: "Andre Fernandes, Keenan Szulik, and Erik Hou"
date: "`r format(Sys.time(),'%m/%d/%Y')`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- ################################### -->
<!-- # Erik's section Begins -->
<!-- ################################### -->

## Introduction

This analysis is motivated by the following research question:

\begin{center}
"If there is any relationship between corruption and parking violations both pre and post 2002 and if there are any other relevant explanatory variables."
\end{center}

The question will be addressed by exploratory data analysis techniques. We are asked to imagine that we have been hired by the World Bank to explore the influence cultural norms and legal enforcement have on controlling corruption. To operationalize the analysis, the assignment looks at the parking behavior of United Nations officials in Manhattan.

Until 2002, UN diplomats are protected by diplomatic immunity; therefore, they were not subject to parking enforcement actions and their actions were solely constrained by cultural norms. In 2002, the parking authority acquired the right to confiscate diplomatic license plates of the violateors. As a result, their parking behavior was constrained by both cultural norms and the legal penalties.

We are given a dataset of a selection of UN diplomatic missions, which includes target variable, *violations*, some essential variables for the analysis, such as country codes, label for pre and pos the parking enforcement change, the corruption index, and other variables.

<!-- ################################### -->
<!-- # Maybe include some methodology and caveats here based on how we decided to approach the analysis -->
<!-- ################################### -->

### Setup

First, we load some of the packages we will need for the analysis and the data into R.

Load the data:
```{r, echo=TRUE}
source("utils/functions.R")
df <- load_rda('data/Corrupt.Rdata')
```

### Overview of the data structure

We have `r nrow(df)` observations.
```{r}
nrow(df)
```

We have `r length(colnames(df))` variables in the dataset:
```{r}
str(df)
```

Look at the summary of the dataset:
```{r}
summary(df)
```

Examine the first ten rows of the dataset:
```{r}
head(df, 10)
```

### Data Selection and Cleaning

From examining the data summary and the first ten rows, we see  many NA values in the key variable fields, such as violations and corruption. Also notice that, in the field prepost, we have blanks. 

It is necessary to clean the data by taking out the records with the essential fields being blank or NA before starting analysis on the variables:

```{r}
df[df=="" | df=="NA"] = NA  #set all the blanks and "NA" to NA

#exlcude the records having NAs in at least one of the essential fields
df_clean = subset(df, !is.na(wbcode) & !is.na(prepost) & !is.na(violations) & !is.na(corruption))

```

One last step before starting univariate analysis of key variables is to make sure in our cleaned dataset, we have exactly two records per country, one pre and one post 2002. Because,
1. With a missing pre or pos record, it would be difficult to make comparisons of countries' behavior pre and post the policy change. 
2. Also, if we had some countries having more than one pre and/or one post record, further cleaning or manipulation would have to take place to make sure we appropriately weigh different observations.


```{r}
nrow(df_clean)  #the total number observations in the data set
length(unique(df_clean$wbcode))  #the total number of unique countries
length(unique(df_clean[df_clean$prepost == "pre",]$wbcode))  #the total number of distinct countries in the data set with prepost == "pre"
length(unique(df_clean[df_clean$prepost == "pos",]$wbcode))  #the total number of distinct countries in the data set with prepost == "pos"

```
From the above numbers, we know that we have a total of `r nrow(df_clean)` observations left in our dataset after cleaning with `r length(unique(df_clean$wbcode))` different counties. Further checking for integrity, we note that, in the dataset, `r length(unique(df_clean[df_clean$prepost == "pre",]$wbcode)) ` unique coutries having prepost field being "pre" and `r length(unique(df_clean[df_clean$prepost == "pos",]$wbcode)) ` unique coutries having prepost field being "pos". Finally, we are sure now that we have a clean enough dataset to start subsequent analysis  


## Univariate Analysis of Key Variables

Now We start the univariate analysis.

### Variable, Violations

First is to look at the variable, violations:

```{r, echo=TRUE}
summary(df_clean$violations)
sd(df_clean$violations)
hist(df_clean$violations,20,xlab = "Violations", main = "Histogram of Violations")
```

There are several features of the variables worth highlighting:

1. All the values are non-negative.
2. From both the histogram and the numeric summary, we can see that the values are very clustered to the lower end where more than 50% of the values are less than 6.
3. The distribution is right-skewed with some really big outliers which causes the mean to be greater than the median and relatively high standard deviation, about 302.

Since there are `r nrow(df_clean[df_clean$violations == 0,])` zeros with many datapoints clustering close to zero with only a few outliers taking much greater values. Try to draw a histogram of $log(volations + 1)$ to help us better visualize the distribution. While drawing the histogram, we adjust the position of the bins so the first bar is centered around zero. 
```{r}
nrow(df_clean[df_clean$violations == 0,])
```
```{r}
hist(log(df_clean$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations")
```

Notice that the frequency distribution has two modes one in (-0.25,0.25) and one in (4.25,4.75). This probably is caused by the change of policy where there were more violations before 2002 and less violation after 2002.

Two histograms of violations before and after the change of policy prove the assumption.
```{r}
hist(log(df_clean[df_clean$prepost == "pre",]$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations until 2002")
hist(log(df_clean[df_clean$prepost == "pos",]$violations+1),breaks = seq(-0.75,10,0.5)+0.5, ylim = c(0,50), xlab = "log(Violations+1)", main = "Histogram of Violations starting 2002")
```

From this above drawing, we demonstrated the shift in the distribution of violation before and after the policy change.
**!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!do we want to use boxplot??!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!**


### Variable, Corruption

Next, we move on to the other key variable, corruption.

First step is to look at the numeric summary of the variable and its histogram:

```{r}
summary(df_clean$corruption)
sd(df_clean$corruption)
hist(df_clean$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))
```

We draw the histograms of corruption of pre and post the policy change separately to compare:


```{r}
hist(df_clean[df_clean$prepost == "pre",]$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption until 2002")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))
hist(df_clean[df_clean$prepost == "pos",]$corruption, breaks = 20, xlab = "Corruption", main = "Histogram of Corruption starting 2002")
axis(1, at = seq(-3,2,by=0.5), labels = seq(-3,2,by=0.5))

```

We notice that the two histograms seem identical, which means most likely, the dataset have corruption as a constant over time. Just to double-check, we test if for each country the corruption is the same pre and post 2002.

```{r}
nrow(unique(df_clean[,c("wbcode", "corruption")]))
```

Draw a boxplot of corruption:

```{r}
boxplot(unique(df_clean[,c("wbcode", "corruption")])$corruption, ylab = "corruption")
```


Several key feature of the variable, corruption:

1. Through making sure that the number of unique combinations of wbcode and corruption is the same as the number of unique wbcodes. We are sure that the dataset has corruption as a constant for each country.
2. We can see that the histogram has two modes one around 0.75 and one around -2.5.
3. The distribution is left-skewed with most countries having the values between 0 and 1 and not too few outliers cluster close to the second mode.
4. For corruption, it might be interesting to see if the outliers themselves share some characteristics in common compared to other countries in the dataset.


<!-- ################################### -->
<!-- # Andre's section Begins -->
<!-- ################################### -->

### Analysis of Key Relationships

Fill in with information.

```{r, echo=TRUE}

```

<!-- ################################### -->
<!-- # Keenan's section Begins -->
<!-- ################################### -->

### Analysis of Secondary Effects

Fill in with information.

```{r, echo=TRUE}

```

### Conclusion

You can also embed plots, for example:

```{r, echo=TRUE}

```

<style>
    body .main-container {
        max-width: 1600px;
    }
</style>